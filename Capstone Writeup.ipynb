{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Credit Card Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: UCI machine learning library, found here: http://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29\n",
    "\n",
    "Project purpose:\n",
    "I am enrolled in the Data Science with Python module under the Thinkful bootcamp program. The project represents a simulation of fraud detection for adding to my project portfolio. An open dataset allows me to practice applying machine learning algorithms through the prediction modeling process. \n",
    "\n",
    "Cases to avoid:\n",
    "I am not interested in decreasing processing time like helping the algorithm converge because the code is not meant to be scaled into production. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Software: Python using packages: sklearn, pandas, numpy, ect\n",
    "\n",
    "Machine learning problem: supervised learning - classification based on 20 variables\n",
    "\n",
    "Algorithm: logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data comes from the UCI repository, but does not have a link for downloading the .csv file. I copied and pasted the data found from the following link into and .xlsx file. With the data in the .xlsx file, I used delimiter for separating the columns by space and typed in each column name. I decided on leaving the categorical value names in instead of replacing with the original names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import pandas package\n",
    "import pandas as pd\n",
    "german_credit = pd.read_csv('German.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dimension of dataset\n",
    "german_credit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 rows by 21 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status checking            object\n",
       "Duration                    int64\n",
       "Credit history             object\n",
       "Purpose                    object\n",
       "Credit amount               int64\n",
       "Savings account/bonds      object\n",
       "Present employment         object\n",
       "Installment rate            int64\n",
       "Personal status/sex        object\n",
       "Debtors/guarantors         object\n",
       "Present resident since      int64\n",
       "Property                   object\n",
       "Age                         int64\n",
       "Other installment plans    object\n",
       "Housing                    object\n",
       "Number existing credits     int64\n",
       "Job                        object\n",
       "Number of people liable     int64\n",
       "Telephone                  object\n",
       "Foreign worker             object\n",
       "Classification              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column datatypes\n",
    "german_credit.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13 categorical values and 7 numeric (excluding the class label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status checking            1000\n",
       "Duration                   1000\n",
       "Credit history             1000\n",
       "Purpose                    1000\n",
       "Credit amount              1000\n",
       "Savings account/bonds      1000\n",
       "Present employment         1000\n",
       "Installment rate           1000\n",
       "Personal status/sex        1000\n",
       "Debtors/guarantors         1000\n",
       "Present resident since     1000\n",
       "Property                   1000\n",
       "Age                        1000\n",
       "Other installment plans    1000\n",
       "Housing                    1000\n",
       "Number existing credits    1000\n",
       "Job                        1000\n",
       "Number of people liable    1000\n",
       "Telephone                  1000\n",
       "Foreign worker             1000\n",
       "Classification             1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of NaN values in each column\n",
    "german_credit.notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No NaN values found in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics of the numeric variables, including the classification label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Installment rate</th>\n",
       "      <th>Present resident since</th>\n",
       "      <th>Age</th>\n",
       "      <th>Number existing credits</th>\n",
       "      <th>Number of people liable</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.903000</td>\n",
       "      <td>3271.258000</td>\n",
       "      <td>2.973000</td>\n",
       "      <td>2.845000</td>\n",
       "      <td>35.546000</td>\n",
       "      <td>1.407000</td>\n",
       "      <td>1.155000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.058814</td>\n",
       "      <td>2822.736876</td>\n",
       "      <td>1.118715</td>\n",
       "      <td>1.103718</td>\n",
       "      <td>11.375469</td>\n",
       "      <td>0.577654</td>\n",
       "      <td>0.362086</td>\n",
       "      <td>0.458487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1365.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2319.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>3972.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>18424.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Duration  Credit amount  Installment rate  Present resident since  \\\n",
       "count  1000.000000    1000.000000       1000.000000             1000.000000   \n",
       "mean     20.903000    3271.258000          2.973000                2.845000   \n",
       "std      12.058814    2822.736876          1.118715                1.103718   \n",
       "min       4.000000     250.000000          1.000000                1.000000   \n",
       "25%      12.000000    1365.500000          2.000000                2.000000   \n",
       "50%      18.000000    2319.500000          3.000000                3.000000   \n",
       "75%      24.000000    3972.250000          4.000000                4.000000   \n",
       "max      72.000000   18424.000000          4.000000                4.000000   \n",
       "\n",
       "               Age  Number existing credits  Number of people liable  \\\n",
       "count  1000.000000              1000.000000              1000.000000   \n",
       "mean     35.546000                 1.407000                 1.155000   \n",
       "std      11.375469                 0.577654                 0.362086   \n",
       "min      19.000000                 1.000000                 1.000000   \n",
       "25%      27.000000                 1.000000                 1.000000   \n",
       "50%      33.000000                 1.000000                 1.000000   \n",
       "75%      42.000000                 2.000000                 1.000000   \n",
       "max      75.000000                 4.000000                 2.000000   \n",
       "\n",
       "       Classification  \n",
       "count     1000.000000  \n",
       "mean         1.300000  \n",
       "std          0.458487  \n",
       "min          1.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          2.000000  \n",
       "max          2.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary statistics\n",
    "german_credit.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms of numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#Duration\n",
    "plt.hist(german_credit['Duration'])\n",
    "plt.xlabel('Duration')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Duration in Months')\n",
    "plt.show()\n",
    "#Credit amount\n",
    "plt.hist(german_credit['Credit amount'])\n",
    "plt.xlabel('Credit amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Credit Amount')\n",
    "plt.show()\n",
    "#Installment rate\n",
    "plt.hist(german_credit['Installment rate'])\n",
    "plt.xlabel('Installment rate')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Installment Rate in % of Disposable Income')\n",
    "plt.show()\n",
    "#Years of present residence - fix \n",
    "plt.hist(german_credit['Present resident since'])\n",
    "plt.xlabel('Present resident since')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Present Residence Since')\n",
    "plt.show()\n",
    "#Age\n",
    "plt.hist(german_credit['Age'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Age')\n",
    "plt.show()\n",
    "#Number of existing credits - fix \n",
    "plt.hist(german_credit['Number existing credits'])\n",
    "plt.xlabel('Number existing credits')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram Of Number Of Existing Credits At This Bank')\n",
    "plt.show()\n",
    "#Number of people liable\n",
    "plt.hist(german_credit['Number of people liable'])\n",
    "plt.xlabel('Number of people liable')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Number of people being liable to provide maintenance for')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of factors in each categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Status checking\n",
    "german_credit['Status checking'].value_counts()\n",
    "#Credit history\n",
    "german_credit['Credit history'].value_counts()\n",
    "#Purpose\n",
    "german_credit['Purpose'].value_counts()\n",
    "#Savings account/bonds\n",
    "german_credit['Savings account/bonds'].value_counts()\n",
    "#Present employment\n",
    "german_credit['Present employment'].value_counts()\n",
    "#Personal status/sex\n",
    "german_credit['Personal status/sex'].value_counts()\n",
    "#Debtors/guarantors\n",
    "german_credit['Debtors/guarantors'].value_counts()\n",
    "#Property\n",
    "german_credit['Property'].value_counts()\n",
    "#Other installment plans\n",
    "german_credit['Other installment plans'].value_counts()\n",
    "#Housing\n",
    "german_credit['Housing'].value_counts()\n",
    "#Job\n",
    "german_credit['Job'].value_counts()\n",
    "#Telephone\n",
    "german_credit['Telephone'].value_counts()\n",
    "#Foreign worker\n",
    "german_credit['Foreign worker'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check balance of class labels for good or bad creditor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "german_credit['Classification'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is unbalanced because there are more observations of the good creditors than bad. There are 700 observations of customers with good credit scores and 300 with bad. 1 represents the primary class because of the greater observations and 2 as the minority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change classification label from (1,2) to (0,1) for aligning with sklearn's documentation. Without doing this, I got higher precision and recall scores after using the logit model. Sklearn’s precision defines identifying 1 correctly as the TP and since 1 is not the class we should predict, got a higher score. The incorrect class label resulted in predicting the occurrence of a good crediter that was 70% of the data instead of the bad creditor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "german_credit['Classification'] = german_credit['Classification'].map(lambda x: x-1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert categorical variables to dummy\n",
    "\n",
    "Logistic regression in sklearn does not automatically convert the categorical variables to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_var = pd.get_dummies(german_credit[['Status checking', 'Credit history', 'Purpose', \n",
    "                              'Savings account/bonds', 'Present employment', \n",
    "                              'Personal status/sex', 'Debtors/guarantors', \n",
    "                              'Property', 'Other installment plans', 'Housing', \n",
    "                              'Job', 'Telephone', 'Foreign worker']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify number of new columns after converting to dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_var.shape   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the 54 factors turned into a binary variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset numeric variables by dropping categorical from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credit_new = german_credit.drop(['Status checking', 'Credit history', 'Purpose', \n",
    "                              'Savings account/bonds', 'Present employment', \n",
    "                              'Personal status/sex', 'Debtors/guarantors', \n",
    "                              'Property', 'Other installment plans', 'Housing', \n",
    "                              'Job', 'Telephone', 'Foreign worker'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dimensions of numeric dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "credit_new.shape                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine numeric and categorical dataframes using .join() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "german_new_credit = dummy_var.join(credit_new)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get demensions of new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "german_new_credit.shape        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn requires the logistic regression fit with a matrix or array. Separate the data into independent (X) and dependent (Y) variables, then convert to matrix format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Subset dataframe into indepedent and dependent variables\n",
    "X = german_new_credit.drop('Classification', axis = 1)\n",
    "Y = german_credit['Classification']\n",
    "#Convert dataframe to matrix \n",
    "X_mat = X.as_matrix()\n",
    "Y_mat = Y.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import logit model in sklearn\n",
    "import sklearn.linear_model as ln\n",
    "#Create logistic regression object\n",
    "logreg = ln.LogisticRegression()\n",
    "#Fit the logistic regression \n",
    "logreg.fit(X_mat, Y_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import k-fold cross validation in sklearn\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "#Accuracy of test set\n",
    "score = cross_val_score(logreg, X_mat, Y_mat, scoring = 'accuracy', cv = 10)\n",
    "np.mean(score)\n",
    "#Recall of test set\n",
    "recall_score = cross_val_score(logreg, X_mat, Y_mat, scoring = 'recall', cv = 10)\n",
    "np.mean(recall_score)\n",
    "#Precision of test set\n",
    "precision_score = cross_val_score(logreg, X_mat, Y_mat, scoring = 'precision', cv = 10)\n",
    "np.mean(precision_score)\n",
    "#AUC\n",
    "auc_score = cross_val_score(logreg, X_mat, Y_mat, scoring = 'roc_auc', cv = 10)\n",
    "np.mean(auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building Version 3 - Fixing Unbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing from pt.1 of combining the categorical and numeric data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UnbalancedDataset package is for python and provides different algorithms for fixing unbalanced datastets. Here’s the link: https://github.com/fmfn/UnbalancedDataset. I applied the SMOTE algorithm to create 400 more observations of variables with the minority class (bad creditors) for a 50/50 distribution of 700 each. I weighted the proportions of the majority to minority class for a 50/50 ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import module for applying oversampling using SMOTE\n",
    "from unbalanced_dataset import SMOTE\n",
    "#Set verbose as false to show less information\n",
    "verbose = False\n",
    "#Ratio of majority to minority class for 50/50 distribution\n",
    "smote = SMOTE(ratio = 1.335, verbose = False, kind = 'regular')\n",
    "#Fit data and transform\n",
    "X_mod = X.as_matrix()\n",
    "Y_mod = np.array(Y)\n",
    "#Create new dataset\n",
    "smox, smoy = smote.fit_transform(X_mod, Y_mod) \n",
    "#Check ratio of good and bad creditors\n",
    "#Convert matrix to dataframe\n",
    "y_data = pd.DataFrame(smoy, columns = ['classification'])\n",
    "#check work\n",
    "y_data['classification'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Evaluation Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create logistic regression object\n",
    "logreg_ov = ln.LogisticRegression()\n",
    "#Model building\n",
    "#Fit the logistic regression \n",
    "logreg_ov.fit(smox, smoy)\n",
    "\n",
    "#Model testing\n",
    "#Accuracy of test set\n",
    "score_ov = cross_val_score(logreg_ov, smox, smoy, scoring = 'accuracy', cv = 10)\n",
    "np.mean(score_ov)\n",
    "#Recall of test set\n",
    "recall_score_ov = cross_val_score(logreg_ov, smox, smoy, scoring = 'recall', cv = 10)\n",
    "np.mean(recall_score_ov)\n",
    "#Precision of test set\n",
    "precision_score_ov = cross_val_score(logreg_ov, smox, smoy, scoring = 'precision', cv = 10)\n",
    "np.mean(precision_score_ov)\n",
    "#AUC\n",
    "auc_score_ov = cross_val_score(logreg_ov, smox, smoy, scoring = 'roc_auc', cv = 10)\n",
    "np.mean(auc_score_ov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building Version 2 - Standardizing Numeric Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are seven numeric variables in the dataframe and wanted to check if standardizing increases accuracy or precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the numeric and categorical data like before. The StandardScaler() function requires the datatype as float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import module for standardizing variables from sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Subset numeric data\n",
    "num_credit = german_credit[['Duration', 'Credit amount', \n",
    "                            'Installment rate', 'Present resident since',\n",
    "                            'Age', 'Number existing credits', 'Number of people liable']]\n",
    "#Apply function to change datatype\n",
    "num_credit_st = num_credit.astype('float')                            \n",
    "#Standardization object and fit to data\n",
    "stan = StandardScaler().fit(num_credit_st)\n",
    "#Transform dataset\n",
    "stan_data = stan.transform(num_credit_st)\n",
    "#Convert array to  dataframe\n",
    "#Get strings of numeric column name_\n",
    "col_names = ['Duration', 'Credit amount', 'Installment rate', 'Present resident since',\n",
    "             'Age', 'Number existing credits', 'Number of people liable']\n",
    "new_stan = pd.DataFrame(stan_data, columns = col_names)                            \n",
    "\n",
    "#Subset categorical data\n",
    "cat_credit = german_credit[['Status checking', 'Credit history', 'Purpose', \n",
    "                              'Savings account/bonds', 'Present employment', \n",
    "                              'Personal status/sex', 'Debtors/guarantors', \n",
    "                              'Property', 'Other installment plans', 'Housing', \n",
    "                              'Job', 'Telephone', 'Foreign worker']]\n",
    "#Change categorical variables to dummy\n",
    "dummy_var = pd.get_dummies(cat_credit)  \n",
    "#Join dataframes together\n",
    "german_new_credit = dummy_var.join(new_stan) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model building and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Subset dataframe into indepedent and dependent variables\n",
    "X_st = german_new_credit\n",
    "Y_st = german_credit['Classification'] \n",
    "\n",
    "#Create logistic regression object\n",
    "logreg_st = ln.LogisticRegression()\n",
    "#Convert dataframe to matrix \n",
    "X_stm = X_st.as_matrix()\n",
    "Y_stm = Y_st.as_matrix()\n",
    "\n",
    "#Fit the logistic regression \n",
    "logreg_st.fit(X_stm, Y_stm)\n",
    "\n",
    "#Accuracy of test set\n",
    "score_st = cross_val_score(logreg_st, X_stm, Y_stm, scoring = 'accuracy', cv = 10)\n",
    "np.mean(score_st)\n",
    "#Recall of test set\n",
    "recall_score_st = cross_val_score(logreg_st, X_stm, Y_stm, scoring = 'recall', cv = 10)\n",
    "np.mean(recall_score_st)\n",
    "#Precision of test set\n",
    "precision_score_st = cross_val_score(logreg_st, X_stm, Y_stm, scoring = 'precision', cv = 10)\n",
    "np.mean(precision_score_st)\n",
    "#AUC\n",
    "auc_score_st = cross_val_score(logreg_st, X_stm, Y_stm, scoring = 'roc_auc', cv = 10)\n",
    "np.mean(auc_score_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Say how standardization did not help the analysis by more than 1000th of a percentage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
